<?xml version="1.0" encoding="utf-8" standalone="no"?>
<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta xmlns="" http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>제16장 Parallel Execution</title><link rel="stylesheet" href="../stylesheet.css" type="text/css"/><meta name="generator" content="DocBook XSL Stylesheets V1.72.0"/><link rel="start" href="index.html" title="Tibero 관리자 안내서"/><link rel="up" href="index.html" title="Tibero 관리자 안내서"/><link rel="prev" href="chapter_tac.html" title="제15장 Tibero Active Cluster"/><link rel="next" href="chapter_apm.html" title="제17장 Tibero Performance Repository"/></head><body><div xmlns="" class="navheader"><table width="100%" summary="Navigation header"><tr><td class="navbar-title" colspan="3" align="center">제16장 Parallel Execution</td></tr><tr><td width="20%" align="left"><a accesskey="p" href="chapter_tac.html">이전</a> </td><td class="navbar-title" width="60%" align="center"> </td><td width="20%" align="right"> <a accesskey="n" href="chapter_apm.html">다음</a></td></tr></table><hr/></div><div class="chapter" lang="ko"><div class="titlepage"><div><div><h2 class="title"><a id="chapter_parallel"/>제16장 Parallel Execution</h2></div></div></div><div class="toc"><p><b>내용 목차</b></p><dl><dt><span class="section"><a href="chapter_parallel.html#d5e13010">16.1. 개요</a></span></dt><dt><span class="section"><a href="chapter_parallel.html#d5e13038">16.2. Degree of Parallelism</a></span></dt><dd><dl><dt><span class="section"><a href="chapter_parallel.html#d5e13063">16.2.1. DOP 결정</a></span></dt><dt><span class="section"><a href="chapter_parallel.html#d5e13081">16.2.2. DOP에 따른 워킹 스레드 할당</a></span></dt></dl></dd><dt><span class="section"><a href="chapter_parallel.html#d5e13089">16.3. 동작 원리</a></span></dt><dd><dl><dt><span class="section"><a href="chapter_parallel.html#d5e13107">16.3.1. 2-set 구조</a></span></dt><dt><span class="section"><a href="chapter_parallel.html#sect_tps">16.3.2. TPS 분배</a></span></dt></dl></dd><dt><span class="section"><a href="chapter_parallel.html#d5e13204">16.4. Parallelism 유형</a></span></dt><dd><dl><dt><span class="section"><a href="chapter_parallel.html#sect_parallel_query">16.4.1. Parallel Query</a></span></dt><dt><span class="section"><a href="chapter_parallel.html#d5e13347">16.4.2. Parallel DDL</a></span></dt><dt><span class="section"><a href="chapter_parallel.html#d5e13355">16.4.3. Parallel DML</a></span></dt></dl></dd><dt><span class="section"><a href="chapter_parallel.html#d5e13392">16.5. Parallel Execution Perfomance 분석을 위한 뷰</a></span></dt></dl></div>
  

  <p>본 장에서는 Parallel Execution의 기본개념과 동작원리를 소개하고 이를 유형별로 실행하는 방법을
  설명한다.</p>

  <div class="section" lang="ko"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="d5e13010"/>16.1. 개요<a id="d5e13012" class="indexterm"/></h2></div></div></div>
    

    <p>Parallel Execution(이하 PE)은 한 개의 작업을 여러 개로 나누어 동시 처리를 실행하는 방법으로 데이터
    웨어하우스(DW: Data Warehouse)와 BI(Business Information)를 지원하는 대용량 DB에서 발생하는
    데이터 처리의 응답 시간을 획기적으로 줄일 수 있다. 또한 OLTP(On-Line Transaction Processing)
    시스템에서도 배치 처리의 성능을 높일 수 있다.</p>

    <p>PE는 시스템 리소스의 활용을 극대화하여 데이터베이스 성능을 향상시키고자 하는 것이 기본 사상이기 때문에 다음과 같은
    작업에 대해 성능 향상을 기대할 수 있다.</p>

    <div class="itemizedlist"><ul type="disc" compact="compact"><li>
        <p>대용량 테이블 또는 파티션 인덱스 스캔(partitioned index scan)이나 조인 등의 쿼리</p>
      </li><li>
        <p>대용량 테이블의 인덱스 생성</p>
      </li><li>
        <p>Bulk insert나 update, delete</p>
      </li><li>
        <p>Aggregations</p>
      </li></ul></div>

    <div class="literallayout"><p/></div>

    <p>PE가 시스템 리소스를 최대한 활용하는 방식인 만큼 잘못 사용했을 때는 리소스 고갈로 중요한 데이터 처리가 지연되거나
    오히려 기대했던 성능이 나오지 못하는 경우가 발생할 수 있기 때문에 사용에 주의가 필요하다.</p>

    <p>PE로 성능 향상을 기대할 수 있는 시스템 구성과 환경은 다음과 같다.</p>

    <div class="itemizedlist"><ul type="disc" compact="compact"><li>
        <p>CPU, 클러스터링 등 시스템 측면의 Parallel 구성</p>
      </li><li>
        <p>충분한 입출력 대역폭</p>
      </li><li>
        <p>여유 있는 CPU 사용률(예: CPU 사용량이 30% 이하일 때)</p>
      </li><li>
        <p>정렬, 해싱 그리고 입출력 버퍼와 같은 작업을 수행하기 충분한 메모리</p>
      </li></ul></div>

    <p/>
  </div>

  <div class="section" lang="ko"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="d5e13038"/>16.2. Degree of Parallelism<a id="d5e13040" class="indexterm"/></h2></div></div></div>
    

    <p>Degree of Parallelism(이하 DOP)이란 하나의 연산에 얼마나 많은 시스템 리소스를 할당하여 동시에
    처리하도록 할 것인지를 결정하기 위해 사용되는 개념으로, 단순하게는 하나의 연산을 함께 수행하는 워킹 스레드(이하 WTHR)의 개수를
    의미하기도 한다.</p>

    <div class="note" style="margin-left: 0in; margin-right: 0in;"><h3 class="title">참고</h3>
      <p>연산<a id="d5e13045" class="indexterm"/>은 order by, full table scan과 같이 하나의 쿼리에서 해당 WTHR에 할당되는 규모의
      작업 단위를 말한다.</p>
    </div>

    <div class="literallayout"><p/></div>

    <p>PE는 하나의 연산을 여러 개의 WTHR로 동시에 수행하도록 하는 <span><strong class="guibutton">intra-operation
    PE</strong></span>와 서로 다른 연산을 파이프 스트림(pipe stream) 방식으로 연결해 동시에 수행하도록 하는
    <span><strong class="guibutton">inter-operation PE</strong></span>로 나눌 수 있다.<a id="d5e13051" class="indexterm"/><a id="d5e13054" class="indexterm"/></p>

    <p><span>Tibero</span>에서는 DOP 크기만큼의 WTHR를 할당하여
    intra-operation PE를 구성하고 inter-operation PE에 대해서는 2-set을 구성하는 방식으로 최적의 PE를
    수행한다. 따라서 PE의 실행 과정을 통제하는 Query Coordinator(이하 QC)는 PE를 위해 최대 2*DOP 개수만큼의
    WTHR를 PE_SLAVE(Parallel Execution Slave)<a id="d5e13059" class="indexterm"/>로 활용하게 된다. 단, 동시에 두 개 이상의 연산을 수행하는 inter-operation PE는 지원하지
    않는다.<a id="d5e13061" class="indexterm"/></p>

    <div class="section" lang="ko"><div class="titlepage"><div><div><h3 class="title"><a id="d5e13063"/>16.2.1. DOP 결정</h3></div></div></div>
      

      <p>하나의 SQL 문장(쿼리)에서 하나의 DOP로 PE를 수행하며 한 쿼리에 여러 개의 Parallel Hint가 있거나,
      Parallel Hint가 있는 동시에 Parallel Option을 가진 테이블을 쿼리에 포함하는 경우 그 중 가장 큰 DOP를
      그 쿼리의 DOP로 결정한다. 명시된 DOP가 0보다 작거나 같은 경우에는 디폴트 값 4로 DOP를 결정한다. DOP는
      Parallel Hint에 명시할 수 있으며, 사용 방법은 "<span>Tibero</span> SQL 참조 안내서"를 참고한다.</p>

      <p>DOP를 결정할 때 참고해야 할 요소는 다음과 같다.</p>

      <div class="itemizedlist"><ul type="disc" compact="compact"><li>
          <p>시스템의 CPU 개수</p>
        </li><li>
          <p>시스템의 최대 프로세스 및 스레드 개수</p>
        </li><li>
          <p>테이블이 분산된 경우 그 테이블이 속해 있는 디스크의 개수</p>
        </li><li>
          <p>데이터의 위치나 쿼리의 종류</p>
        </li><li>
          <p>객체 파티션 개수</p>
        </li></ul></div>

      <p>보통 한 사용자만 PE를 수행한다고 하면 정렬과 같은 CPU bound 작업은 CPU 개수의 1~2배로 DOP를
      설정하는 것이 적당하고, 테이블 스캔과 같은 I/O bound 작업은 디스크 드라이브 개수의 1~2배로 DOP를 설정하는 것이
      적당하다. 이처럼 쿼리의 종류와 시스템 환경을 고려하여 DOP를 설정하면 PE를 통해 더 나은 성능을 기대할 수
      있다.</p>

      <p/>
    </div>

    <div class="section" lang="ko"><div class="titlepage"><div><div><h3 class="title"><a id="d5e13081"/>16.2.2. DOP에 따른 워킹 스레드 할당</h3></div></div></div>
      

      <p><span>Tibero</span>에서는 쿼리를 수행하는 과정에서 Parallel 연산을 수행할
      차례가 되면 QC가 계산된 DOP 만큼의 WTHR를 요청하고, 이에 가용한 만큼의 WTHR를 PE_SLAVE로 얻어오게
      된다.</p>

      <p>다음과 같이 연산 하나로 수행하는 쿼리는 DOP 개수만큼 WTHR를 가져와서 하나의 연산을 담당할 하나의
      PE_SLAVE set을 구성한다. 그 이외는 2*DOP 개수만큼 WTHR를 얻어오고 두 개의 PE_SLAVE set을 구성한다.
      이때 WTHR의 개수가 사용자가 명시한 DOP로 수행하기에 부족하면 사용할 수 있는 WTHR만 가지고서 DOP를 재정의하여
      수행하게 된다.</p>

      <pre class="programlisting">SELECT * FROM table1;</pre>

      <div class="literallayout"><p/></div>

      <p>예를 들어 DOP를 4로 결정하여 힌트에 명시한 경우 2*DOP만큼의 WTHR가 필요한 상황이고 WTHR가 5개뿐이라면
      DOP를 2로 재정의하고 4개의 WTHR를 얻어와 PE를 수행한다. 또는 사용 가능한 WTHR가 1개뿐이라면 Parallel
      Plan을 만들었더라도 차례로 수행한다. 즉, PE를 수행하지 않는다. 그리고 QC가 얻어온 PE_SLAVE는 쿼리 수행이 끝나면
      다시 활용이 가능한 WTHR로 반환되며 다음 쿼리 수행을 위해 리소스를 점유하지 않게 되어 있다.</p>
    </div>
  </div>

  <div class="section" lang="ko"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="d5e13089"/>16.3. 동작 원리</h2></div></div></div>
    

    <p><span>Tibero</span>에서는 Parallel Hint가 있거나 Parallel
    Option이 있는 테이블을 포함한 쿼리를 실행하면, Parallel Plan을 작성하게 된다. 이때 생성된 Parallel
    Plan의 수행 순서는 다음과 같다.</p>

    <div class="orderedlist"><ol type="1" compact="compact"><li>
        <p>SQL을 수행하는 WTHR가 QC 역할을 담당한다.</p>
      </li><li>
        <p>parallel operator가 있으면 QC는 DOP에 따라 필요한 만큼의 WTHR를 PE_SLAVE로 얻어
        온다.</p>
      </li><li>
        <p>PE 수행에 필요한 만큼의 WTHR가 확보되지 않으면 사용자에게 알리지 않고 내부에서 차례로 처리한다.</p>
      </li><li>
        <p>QC는 순서에 따라 연산이 2-set 구조를 기반으로 수행되도록 PE_SLAVE를 통제하는 역할을
        담당한다.</p>
      </li><li>
        <p>쿼리 수행이 끝나면 QC는 PE_SLAVE에게서 취합한 쿼리 결과를 사용자에게 보내고, 작업을 종료한
        PE_SLAVE를 다시 사용 가능한 WTHR로 반환한다.</p>
      </li></ol></div>

    <p/>

    <p/>

    <p/>

    <div class="section" lang="ko"><div class="titlepage"><div><div><h3 class="title"><a id="d5e13107"/>16.3.1. 2-set 구조</h3></div></div></div>
      

      <p>PE는 QC가 생성한 실행 계획을 모든 PE_SLAVE가 공유하도록 구성되어 있으며 각 PE_SLAVE는 실행 계획의
      특정 부분만을 실행하도록 QC가 메시지로 제어한다.</p>

      <p>PE는 같은 부분의 실행 계획을 DOP 개수만큼의 PE_SLAVE로 나누어 수행하는 intra-parallelism을
      지원한다. 이렇게 같은 연산을 수행하는 PE_SLAVE의 묶음을 <span><strong class="guibutton">PE_SLAVE
      set</strong></span><a id="d5e13112" class="indexterm"/>라고 한다. PE는 한 번에 최대 2개의 PE_SLAVE set을 구성함으로써 전체 실행 계획 중 서로
      다른 두 개의 연산을 동시에 수행하는 inter-parallelism을 지원한다.</p>

      <p>동시에 수행되는 PE_SLAVE set는 Producer set와 Consumer set으로 나뉜다.</p>

      <div class="informaltable">
        <table border="1"><colgroup><col width="150" align="left"/><col/></colgroup><thead><tr><th align="left">구분</th><th>설명</th></tr></thead><tbody><tr><td align="left">Producer set<a id="d5e13125" class="indexterm"/></td><td>특정 부분의 실행 계획을 수행하면서 로우(중간 결과)를 추출하여 실행 계획에 명시된 방법에 따라
              Consumer set의 PE_SLAVE에게 나눠준다.</td></tr><tr><td align="left">Consumer set<a id="d5e13131" class="indexterm"/></td><td>Producer set로부터 로우를 받아 주어진 연산을 수행하고 나면 다시 producer로 역할이
              바뀌게 된다. PE_SLAVE set는 producer일 때만 결과를 다음 수행 계획을 갖고 있는 Consumer
              set에 전달하며 이러한 PE_SLAVE set을 어떤 순서로 실행 계획 중 어느 부분을 할당해 줄지는 QC가
              제어한다.</td></tr></tbody></table>
      </div>

      <p/>

      <p>다음은 2-set 구조와 Producer set, Consumer set를 설명하는 그림이다.</p>

      <div class="figure"><a id="fig_parallel_execution"/><p class="title"><b>[그림 16.1] Parallel Execution</b></p><div class="figure-contents">
        

        <div xmlns="" class="mediaobject" align="left"><table border="0" summary="manufactured viewport for HTML img" cellspacing="0" cellpadding="0" width="550"><tr><td align="left"><img src="resources/parallel-execution.png" align="top" width="550" alt="Parallel Execution"/></td></tr></table></div>
      </div></div><br class="figure-break"/>

      <p>위 <a href="chapter_parallel.html#fig_parallel_execution" title="[그림 16.1] Parallel Execution">[그림 16.1]</a>의 쿼리에서 Parallel Hint에
      의해 DOP를 고려한 PE 실행 계획이 만들어지면 각각의 연산이 4개(최종으로 결정된 DOP)의 작업 단위로 분할된다. 다시 말해
      각각의 PE가 4개의 스레드를 가지기 때문에 하나의 PE_SLAVE set이 4개의 PE_SLAVE로 구성되고, 이를 다시
      Producer set와 Consumer set의 2-set 구조로 만들기 위해 총 8(= 2 x 4)개의 PE_SLAVE가
      할당된다.</p>

      <p>이때 할당된 2-set의 PE_SLAVE을 각각 set1, set2라고 하면 각 set가 수행하는 역할에 따라
      Producer Set(<span>Tibero</span> Producer Set, 이하 TPS)와 Consumer
      Set(<span>Tibero</span> Consumer Set, 이하 TCS)로 전환되면서 전체 실행
      계획이 수행된다. 즉, TCS가 해시 조인을 처리하기 위해 TPS가 T1 테이블에 스캔을 통해 로우를 공급해 주기를 기다리게 되며
      TPS가 테이블 스캔을 시작함으로써 PE 실행 계획에 대한 작업이 시작된다.</p>

      <p>set1이 TPS를 담당하여 T1을 스캔하고 set2가 TCS를 담당하여 set1이 보내는 로우에 대해 해시 테이블을
      구성하게 되며, set1이 T1 스캔을 마치면 계속해서 T2 스캔을 수행하면서 TCS를 담당하는 set2에게 로우를 공급한다.
      set1이 T2의 스캔을 마치게 되면 TCS로 역할이 전환되면서 sort group by를 수행하게 되고, 반대로 set2는
      TPS로 역할이 전환되면서 해시 조인의 결과를 set1에 공급한다. 마지막으로 set1이 TPS가 되어 sort group by
      수행의 결과를 QC에게 보낸다.</p>

      <p>이것이 2-set 구조를 이용하여 PE의 실행 계획에서 각각의 연산을 병렬로 수행하는 intra-operation
      parallelism을 수행하면서 동시에 다양한 연산을 교차하여 inter-operation parallelism을 수행하도록
      하는 기본 동작 원리이다.</p>
    </div>

    <div class="section" lang="ko"><div class="titlepage"><div><div><h3 class="title"><a id="sect_tps"/>16.3.2. TPS 분배</h3></div></div></div>
      

      <p>TPS는 TCS에 연산의 결과물을 공급하여 TCS가 다음 연산을 처리할 수 있도록 한다. TPS가 결과물을 분배하는데
      <span>Tibero</span>는 hash, range, broadcast,
      round-robin, send idxm 5가지 방식을 지원하고 있다. 주로 hash, range, broadcast가 자주
      사용된다.</p>

      <div class="informaltable">
        <table border="1"><colgroup><col width="120" align="left"/><col/></colgroup><thead><tr><th align="left">분배방식</th><th>설명</th></tr></thead><tbody><tr><td align="left">hash<a id="d5e13163" class="indexterm"/></td><td>TCS가 hash join, hash group by 등의 해시 기반의 연산을 담당하는 경우에
              사용한다. send key의 hash value에 따라 해당 로우가 보내질 consumer 스레드가
              정해진다.</td></tr><tr><td align="left">range<a id="d5e13169" class="indexterm"/></td><td>TCS가 order by, sort group by와 같은 정렬 기반의 연산을 담당하는 경우에
              사용한다. send key 값의 range에 따라 해당 로우가 보내질 consumer 스레드가
              정해진다.</td></tr><tr><td align="left">broadcast<a id="d5e13175" class="indexterm"/></td><td>Nested Loop 조인이나 pq_distribute 힌트를 사용하여 broadcast를 강제하는
              조인을 TCS가 담당하는 경우에 사용한다. 자세한 내용은 <a href="chapter_parallel.html#sect_parallel_query" title="16.4.1. Parallel Query">“16.4.1. Parallel Query”</a>를 참고한다. 모든 consumer 스레드에 로우가
              보내진다.</td></tr><tr><td align="left">round-robin<a id="d5e13182" class="indexterm"/></td><td>로우를 보낼 consumer를 round-robin 방식으로 실행할 때 사용한다.</td></tr><tr><td align="left">send idxm<a id="d5e13188" class="indexterm"/></td><td>Parallel DML에서 인덱스와 참조 제약조건을 위해 로우를 보낼 때 사용한다.</td></tr></tbody></table>
      </div>

      <div class="literallayout"><p/></div>

      <p>본 절에서는 <a href="chapter_parallel.html#fig_parallel_operation" title="[그림 16.2] Parallel Operations">[그림 16.2]</a>에서와 같이 range 방식을
      예를 들어 설명한다.</p>

      <div class="figure"><a id="fig_parallel_operation"/><p class="title"><b>[그림 16.2] Parallel Operations</b></p><div class="figure-contents">
        

        <div xmlns="" class="mediaobject" align="left"><table border="0" summary="manufactured viewport for HTML img" cellspacing="0" cellpadding="0" width="550"><tr><td align="left"><img src="resources/parallel-operations.png" align="top" width="550" alt="Parallel Operations"/></td></tr></table></div>
      </div></div><br class="figure-break"/>

      <p>DOP가 4로 결정된 PE 실행 계획에서 inter-operation parallelism으로 TPS와 TCS 2개의
      set가 상호 연동하는 방식을 선택하면 총 PE_SLAVE 8개가 전체 PE 수행에 참여하게 된다.</p>

      <p>PE_SLAVE set 하나가 TPS가 되어 테이블 스캔을 하고 TCS로 설정된 다른 set가 order by를 수행할
      수 있도록 로우를 공급해 준다. 이때 4개의 PE_SLAVE는 각각 A~G, H~M, N~S 그리고 T~Z로 정렬 키에 대한
      범위를 정하여 정렬하게 되며, 이에 맞게 TPS는 range 방식으로 해당 로우가 담당하는 PE_SLAVE에 전달될 수 있도록
      한다.</p>

      <p>TCS가 정렬 작업을 완료하고 나면 TPS로 역할이 전환되면서 PE_SLAVE가 설정된 range의 순서대로 정렬
      결과를 QC에게 전달함으로써 전체 데이터에 대한 결과가 얻어진다.</p>

      <p/>
    </div>
  </div>

  <div class="section" lang="ko"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="d5e13204"/>16.4. Parallelism 유형</h2></div></div></div>
    

    <p><span>Tibero</span>가 제공하는 parallel 연산은 다음과 같다.</p>

    <div class="itemizedlist"><ul type="disc" compact="compact"><li>
        <p>액세스 방법</p>

        <p>테이블 스캔 그리고 index fast full scan 등</p>
      </li><li>
        <p>조인 방법</p>

        <p>Nested Loop, Sort Merge, 해시 조인</p>
      </li><li>
        <p>DDL</p>

        <p>CREATE TABLE AS SELECT, CREATE INDEX, REBUILD INDEX, REBUILD
        INDEX PARTITION</p>
      </li><li>
        <p>DML</p>

        <p>INSERT AS SELECT, UPDATE, DELETE</p>
      </li><li>
        <p>기타 연산</p>

        <p>GROUP BY, ORDER BY, SELECT DISTINCT, UNION, UNION ALL,
        Aggregations</p>
      </li></ul></div>

    <div class="section" lang="ko"><div class="titlepage"><div><div><h3 class="title"><a id="sect_parallel_query"/>16.4.1. Parallel Query</h3></div></div></div>
      

      <p>Parallel Hint가 사용되었거나 Parallel Option이 있는 테이블에 쿼리를 수행하면 <span>Tibero</span>는 Parallel Plan을 만들어 낸다. 단, Parallel로 수행하기 충분한 WTHR가 있을 때만
      Parallel Plan대로 PE를 수행한다.</p>

      <pre class="programlisting">SQL&gt; select /*+ parallel (3) */ * from t1;
SQL&gt; create table t1 (a number, b number) parallel 3;
SQL&gt; select * from t1;</pre>

      <div class="literallayout"><p/></div>

      <h4><a id="d5e13230"/>Autotrace(explain plan)<a id="d5e13231" class="indexterm"/><a id="d5e13234" class="indexterm"/></h4>

      <p>Parallel Query에서는 Autotrace(explain plan)를 이용하여 Parallel Plan을 확인할
      수 있다.</p>

      <pre class="programlisting">SQL&gt; set autot on
     select * from t1;

Explain Plan
--------------------------------------------------------------------------------
1  PE MANAGER 
2    PE SEND QC (RANDOM)
3      PE BLOCK ITERATOR
4        TABLE ACCESS (FULL): T1</pre>

      <p>위의 실행 계획에서는 PE SEND와 PE RECV(또는 leaf 노드) 사이를 하나의 PE_SLAVE라고 볼 수
      있으며 PE_SLAVE의 최상단에는 PE SEND가 있어 TPS인 경우 TCS에게 로우를 분배한다.</p>

      <div class="informaltable">
        <table border="1"><colgroup><col width="150" align="left"/><col/></colgroup><thead><tr><th align="left">항목</th><th>설명</th></tr></thead><tbody><tr><td align="left">PES(Parallel Execution Set)</td><td>Parallel Plan에서 하나의 PE_SLAVE set가 수행될 단위를 의미한다. 이를
              PE_SLAVE라고도 부른다. Parallel Execution에서 하나의 연산을 하나의 PE_SLAVE set이
              담당하지 않는다.<a id="d5e13250" class="indexterm"/></td></tr><tr><td align="left">producer slave</td><td>Producer set의 PE_SLAVE이다. <a id="d5e13255" class="indexterm"/></td></tr><tr><td align="left">consumer slave</td><td>Consumer set의 PE_SLAVE이다. <a id="d5e13260" class="indexterm"/></td></tr></tbody></table>
      </div>

      <p/>

      <div class="literallayout"><p/></div>

      <p>PE_SLAVE의 최하단에는 로우를 만드는 테이블 스캔(또는 index fast full scan) 연산자가 있거나
      PE RECV가 있다. PE RECV는 PE_SLAVE가 TCS일 때 TPS가 분배하는 로우를 받아들인다.</p>

      <p>예를 들면 다음과 같다.</p>

      <pre class="programlisting">SQL&gt; select /*+ parallel (3) use_hash(t2) ordered */ * 
from t1, t2 
where t1.a=t2.c;
 
Explain Plan
--------------------------------------------------------------------------------
1  PE MANAGER 
2    PE SEND QC (RANDOM) 
3      HASH JOIN (BUFFERED 
4        PE RECV 
5          PE SEND (HASH) 
6            PE BLOCK ITERATOR 
7              TABLE ACCESS (FULL): T1 
8        PE RECV 
9          PE SEND (HASH) 
10            PE BLOCK ITERATOR 
11              TABLE ACCESS (FULL): T2</pre>

      <div class="informaltable">
        <table border="1"><colgroup><col width="150" align="left"/><col/></colgroup><thead><tr><th align="left">항목</th><th>설명</th></tr></thead><tbody><tr><td align="left">PE MANAGER</td><td><p>PE를 시작하고 PE_SLAVE set을 coordination하는 연산이다.
              </p><p>Serial Execution과 Parallel Execution 사이의 경계로 이 연산
              아래부터는 Parallel로 수행된다.</p></td></tr><tr><td align="left">PE SEND</td><td><p>producer slave가 로우를 분배하는 연산이다.
              </p><p>PE_SLAVE 간의 분배 방법으로는 hash, range, broadcast,
              round-robin, send idxm이 있다. 자세한 내용은 <a href="chapter_parallel.html#sect_tps" title="16.3.2. TPS 분배">“16.3.2. TPS 분배”</a>를
              참고한다.</p><p>PE_SLAVE에서 QC로 로우를 보내는 방법은 다음과
              같다.</p><div class="itemizedlist"><ul type="circle" compact="compact"><li style="list-style-type: circle">
                    <p>QC random : QC 역할을 하는 스레드에 순서와 상관없이 보낸다.</p>
                  </li><li style="list-style-type: circle">
                    <p>QC order : QC 역할을 하는 스레드에 Producer가 순서에 맞게
                    보낸다.</p>
                  </li></ul></div></td></tr><tr><td align="left">PE RECV</td><td>consumer slave에서 producer slave가 PE SEND를 통해 분배한 로우를
              받아들이는 역할을 하는 연산이다.</td></tr><tr><td align="left">PE BLOCK ITERATOR</td><td>테이블 스캔, 인덱스 스캔에서 사용할 <span><strong class="guibutton">granule</strong></span>을 요청하고
              받는 역할을 하는 연산이다. granule<a id="d5e13299" class="indexterm"/>는 PE를 수행할 때 각 PE_SLAVE에 할당되는 일의 단위 크기로 크기를 어느 정도로
              하느냐에 따라 PE의 성능에 영향을 미친다.</td></tr><tr><td align="left">PE IDXM</td><td>Parallel DML에서 인덱스와 참조 제약조건을 하는 연산이다.</td></tr></tbody></table>
      </div>

      <p/>

      <p/>

      <div class="literallayout"><p/></div>

      <h4><a id="d5e13307"/>Nested Loop<a id="d5e13308" class="indexterm"/><a id="d5e13311" class="indexterm"/></h4>

      <p>연산의 특성상 조인의 양쪽 child를 독립된 PES로 구분하지 않고 한쪽 child를 조인하는 PES와 합쳐 하나의
      PES에서 수행되도록 하며, 반대편 child에서 PE SEND를 broadcast 방식으로 PE를 수행한다.</p>

      <pre class="programlisting">SQL&gt; SELECT /*+parallel(3) use_nl(t1 t2) ordered*/ * 
     FROM t1, t2 
     WHERE a &lt; c; 
 
Explain Plan
--------------------------------------------------------------------------------
1 PE MANAGER  
2  PE SEND QC (RANDOM)  
3    NESTED LOOPS   
4      BUFF  
5        PE RECV  
6          PE SEND (BROADCAST)  
7            PE BLOCK ITERATOR  
8              TABLE ACCESS (FULL): T1  
9      PE BLOCK ITERATOR  
10        TABLE ACCESS (FULL): T2 </pre>

      <div class="literallayout"><p/></div>

      <p>보통은 오른쪽 child를 조인 연산을 수행하는 slave에 포함시켜 수행하는 Parallel Plan을 만든다.
      하지만 pq_distribute 힌트를 이용하여 어느 쪽 child를 합칠 것인지를 정하면 PE의 성능을 개선할 수
      있다.</p>

      <pre class="programlisting">SQL&gt; SELECT /*+parallel(3) pq_distribute(t2 broadcast none) use_nl(t2) ordered*/ * 
     FROM t1, t2 
     WHERE a=c; 
 
Explain Plan
--------------------------------------------------------------------------------
1 PE MANAGER 
2  PE SEND QC (RANDOM) 
3    NESTED LOOPS 
4      BUFF 
5        PE RECV 
6          PE SEND (BROADCAST) 
7            PE BLOCK ITERATOR 
8              TABLE ACCESS (FULL): T1 
9      PE BLOCK ITERATOR 
10        TABLE ACCESS (FULL): T2</pre>

      <div class="literallayout"><p/></div>

      <pre class="programlisting">SQL&gt; SELECT /*+parallel(3) pq_distribute (t2 none broadcast) use_nl(t2) ordered*/ * 
     FROM t1, t2 
     WHERE a=c;
 
Explain Plan
--------------------------------------------------------------------------------
1 PE MANAGER 
2  PE SEND QC (RANDOM) 
3    NESTED LOOPS  
4      PE BLOCK ITERATOR 
5        TABLE ACCESS (FULL): T1 
6      TABLE ACCESS (FULL): T2</pre>

      <div class="literallayout"><p/></div>

      <h4><a id="d5e13321"/>제약 사항</h4>

      <p>다음의 연산은 Parallel로 수행하지 않는다.</p>

      <div class="itemizedlist"><ul type="disc" compact="compact"><li>
          <p>rownum을 생성하는 연산</p>
        </li><li>
          <p>cube, rollup을 포함한 group by</p>
        </li><li>
          <p>분석 함수를 포함한 연산</p>
        </li><li>
          <p>top-N order by</p>

          <p>예를 들면 다음과 같다.</p>

          <pre class="programlisting">SQL&gt; SELECT * FROM (select * from t1 order by t1.a)
     WHERE rownum &lt; 5;</pre>
        </li><li>
          <p>임시 테이블에 대한 테이블 스캔</p>
        </li><li>
          <p>dynamic performance view에 대한 스캔</p>
        </li><li>
          <p>외부 테이블에 대한 스캔</p>
        </li><li>
          <p>DBLink를 수행하는 연산</p>

          <div class="itemizedlist"><ul type="circle" compact="compact"><li>
              <p>index range scan, index full scan, index skip scan, index
              unique scan</p>
            </li><li>
              <p>connect by</p>
            </li></ul></div>
        </li></ul></div>
    </div>

    <div class="section" lang="ko"><div class="titlepage"><div><div><h3 class="title"><a id="d5e13347"/>16.4.2. Parallel DDL</h3></div></div></div>
      

      <p><span>Tibero</span>는 <span><strong class="guibutton">'create table ... as
      select, create index, rebuild index'</strong></span>를 Parallel로 수행할 수
      있다.</p>

      <p>'create table ... as select'는 의사 결정 지원 애플리케이션(decision support
      application)에서 요약 테이블을 만들 때 유용하게 사용할 수 있으며 select 부분과 insert 부분을
      Parallel로 처리하여 보다 빠른 DDL의 수행을 기대할 수 있다.</p>

      <p>DDL 문에 Parallel Option을 명시하는 방법으로 사용할 수 있으며 DDL과 관련된 문법은 "<span>Tibero</span> SQL 참조 안내서"를 참고한다.</p>
    </div>

    <div class="section" lang="ko"><div class="titlepage"><div><div><h3 class="title"><a id="d5e13355"/>16.4.3. Parallel DML</h3></div></div></div>
      

      <p><span>Tibero</span>는 insert, update, delete 문에 대해
      Parallel DML을 지원하지만 <span><strong class="guibutton">'insert into ... values ...'</strong></span>
      문의 Parallel DML은 지원하지 않는다. Parallel DML은 주로 큰 데이터를 insert, update,
      delete 처리하는 배치 작업에 유용하게 사용한다. 다시 말해 트랜잭션이 적은 작업에는 효과적이지 않다.</p>

      <div class="literallayout"><p/></div>

      <h4><a id="d5e13361"/>Enable Parallel DML</h4>

      <p>Parallel DML을 <span><strong class="guibutton">'alter session enable parallel
      dml'</strong></span>로 설정한 후 insert, update, delete 문 뒤에 Parallel Hint를 사용해야
      DML을 Parallel로 수행한다. 'enable parallel dml'을 하지 않으면 DML 문에 힌트를 명시해도
      Parallel로 수행하지 않는다. 즉, 'disable parallel dml'로 Parallel DML을 못하도록 설정할 수
      있다.</p>

      <p>Parallel DML은 DOP + 1 개의 트랜잭션으로 동작하며 커밋은 Two-phase commit으로 이루어진다.
      롤백 또한 DML이 여러 개의 트랜잭션으로 이루어졌기 때문에 Parallel로 진행된다.</p>

      <p>Parallel DML은 여러 개의 트랜잭션으로 진행되기 때문에 Parallel DML 후 커밋 이전까지는 같은
      세션에서 select 문으로 해당 테이블을 조회할 수 없으며 Parallel DML로 수정된 테이블에 대한 조회는 커밋 후에
      가능하다.</p>

      <pre class="programlisting">SQL&gt; alter session enable parallel dml;
SQL&gt; insert /*+ parallel (3) */ into PE_test3 select * from PE_test3;
10001 rows created.
 
SQL&gt; select * from PE_test3;
TBR-12066: Unable to read or modify an object after modifying it with PDML.
 
SQL&gt; insert /*+ parallel (3) */ into PE_test3 select * from PE_test3;
TBR-12067: Unable to modify an object with PDML after modifying it.</pre>

      <div class="literallayout"><p/></div>

      <h4><a id="d5e13368"/>insert</h4>

      <p>select 서브 쿼리에 Parallel Hint를 주어 insert뿐만 아니라 insert할 로우를 추출하는
      select도 Parallel로 수행하여 더 빠르게 DML을 수행할 수 있다.</p>

      <pre class="programlisting">SQL&gt; insert /*+ parallel (3) */ into PE_test3
      select /*+ parallel (3) */ * from PE_test3;

10001 rows created.</pre>

      <div class="literallayout"><p/></div>

      <h4><a id="d5e13372"/>제약 사항</h4>

      <p>다음의 경우는 Parallel DML로 수행하지 않는다.</p>

      <div class="itemizedlist"><ul type="disc" compact="compact"><li>
          <p>insert into ... values ... 문인 경우</p>
        </li><li>
          <p>반환문이 있는 DML인 경우</p>
        </li><li>
          <p>Parallel DML로 수정된 테이블인 경우 커밋을 하기 전까지는 같은 세션에서 DML이나 쿼리로 접근할 수
          없다.</p>
        </li><li>
          <p>트리거가 있는 테이블에 대한 DML인 경우</p>
        </li><li>
          <p>LOB 타입의 컬럼이 있는 테이블에 대한 DML인 경우</p>
        </li><li>
          <p>self reference, delete cascade 제약조건이 있는 DML인 경우</p>
        </li><li>
          <p>online rebuild 중인 인덱스를 갖는 테이블에 대한 DML인 경우</p>
        </li><li>
          <p>Standby가 있는 경우</p>
        </li></ul></div>

      <p/>

      
    </div>
  </div>

  <div class="section" lang="ko"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="d5e13392"/>16.5. Parallel Execution Perfomance 분석을 위한 뷰<a id="d5e13394" class="indexterm"/></h2></div></div></div>
    

    <p><span>Tibero</span>가 제공하는 parallel 관련 뷰는 다음과 같다.</p>

    <div class="informaltable">
      <table border="1"><colgroup><col width="150" align="left"/><col/></colgroup><thead><tr><th align="left">뷰</th><th>설명</th></tr></thead><tbody><tr><td align="left">V$PE_SESSION<a id="d5e13408" class="indexterm"/></td><td>쿼리 서버 세션에 관한 데이터를 보여준다. 현재 Parallel Execution을 하고 있는 세션에 관한
            정보를 실시간으로 보여주며, 요청된 DOP와 해당 연산에 허가된 실제 DOP도 보여준다. 추가적으로 다른 정보를 더
            확인하기 위해서는 동일한 SID로 V$SESSION을 확인한다.</td></tr><tr><td align="left">V$PE_TQSTAT<a id="d5e13414" class="indexterm"/></td><td><p>Parallel Execution 동안의 traffic을 Table queue 수준에서
            보여준다. Table queue는 쿼리 서버간 또는 쿼리 서버와 Coodinator간의 파이프
            라인이다.</p><p>이 뷰를 통해 각 producer에서 consumer로 간 데이터의 수와 크기를
            확인하고, 로드가 균형있게 처리되고 있는지를 확인할 수 있다. 이 뷰는 해당 세션에서 Parallel
            Execution을 실행했을 때 값을 가지게 되며, 해당 세션에서 실행한 마지막 Parallel Execution에
            대한 정보를 갖고 있다.</p></td></tr><tr><td align="left">V$PE_PESSTAT<a id="d5e13422" class="indexterm"/></td><td><p>Parallel Execution이 진행되는 동안 각 스텝에서의 소요시간을 나타낸다. 각 스텝은
            producer에서 consumer로 데이터 전송이 끝나고 consumer가 새로운 producer가 되거나
            producer에서 coodinator로 데이터 전송이 끝날 때까지를 의미한다. </p><p>이 뷰를
            통해서는 각 producer, consumer에서 수행한 연산을 확인하기 어렵기 때문에 V$PE_PESPLAN 뷰를
            사용할 것을 권장한다. V$PE_PESSTAT, V$PE_PESPLAN 두 뷰 모두 V$PE_TQSTAT 뷰와 동일하게
            해당 세션에서 마지막으로 수행한 Parallel Execution에 대한 정보를 갖고 있다. 만약 해당 세션에서
            Parallel Execution을 수행한 적이 없을 경우 데이터가 존재하지 않는다.</p></td></tr><tr><td align="left">V$PE_PESPLAN<a id="d5e13430" class="indexterm"/></td><td>해당 세션에서 마지막으로 수행한 Parallel Execution의 플랜과 Parallel
            Execution의 수행시간을 보여준다. 어떤 연산이 Parallel로 진행되었고 consumer로의 데이터 전송이
            얼마나 걸렸는지 알 수 있고 producer에서 range 방식으로 send할 경우 샘플 수집 시간도
            보여준다.</td></tr></tbody></table>
    </div>
  </div>
</div><div class="navfooter"><hr/><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="chapter_tac.html">이전</a> </td><td width="20%" align="center"> </td><td width="40%" align="right"> <a accesskey="n" href="chapter_apm.html">다음</a></td></tr><tr><td width="40%" align="left" valign="top">제15장 <span>Tibero</span> Active Cluster </td><td width="20%" align="center"><a accesskey="h" href="index.html">처음으로</a></td><td width="40%" align="right" valign="top"> 제17장 <span>Tibero</span> Performance Repository</td></tr></table></div><div xmlns="" align="center"/></body></html>